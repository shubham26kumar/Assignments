{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf03d43-b150-46a9-b2c4-2e5fb2fd5a37",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with \n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946f16a-0950-4af3-9ee1-260ad960a333",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical concepts used to describe the probability distribution of a discrete random variable (PMF) or a continuous random variable (PDF). They provide a way to understand how likely different outcomes are in a given probability distribution.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "The PMF is used to describe the probabilities of individual discrete outcomes of a random variable. It gives the probability of the random variable taking on a specific value. Mathematically, for a discrete random variable \"X,\" the PMF is denoted as P(X=x), where \"x\" is a specific value of the random variable.\n",
    "\n",
    "For example, consider rolling a fair six-sided die. The PMF of the outcome \"X\" (the number rolled) can be represented as:\n",
    "\n",
    "P(X=1) = 1/6\n",
    "P(X=2) = 1/6\n",
    "P(X=3) = 1/6\n",
    "P(X=4) = 1/6\n",
    "P(X=5) = 1/6\n",
    "P(X=6) = 1/6\n",
    "\n",
    "Here, each P(X=x) represents the probability of rolling a specific number on the die.\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "\n",
    "The PDF is used to describe the probability distribution of continuous random variables. Unlike discrete random variables, continuous random variables can take on an infinite number of possible values within a certain range. The PDF gives the relative likelihood of the random variable falling within a particular range of values. Mathematically, for a continuous random variable \"Y,\" the PDF is denoted as f(Y=y), where \"y\" is a specific value or range of values.\n",
    "\n",
    "For example, consider the height of people in a certain population. The PDF of the height \"Y\" can be represented as a function that describes how the heights are distributed across the range of possible values.\n",
    "\n",
    "It's important to note that while the PMF gives actual probabilities for specific discrete values, the PDF gives probabilities per unit of value in the continuous case. The area under the PDF curve within a specific range corresponds to the probability that the random variable falls within that range.\n",
    "\n",
    "In summary, the PMF is used for discrete random variables and gives probabilities for individual values, while the PDF is used for continuous random variables and provides probabilities per unit of value. Both PMF and PDF are fundamental concepts in probability theory and are essential for understanding and modeling various types of random variables and their distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da1a94-0f39-4ffb-b356-24171e3b6a8e",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb9453-d2f3-4bf2-b4c1-1dc89af0d1b0",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "The Cumulative Distribution Function (CDF) is a fundamental concept in probability and statistics that provides a way to describe the cumulative probability of a random variable taking on a value less than or equal to a given value. It gives a complete picture of the probability distribution by showing how the probability accumulates as the value of the random variable changes.\n",
    "\n",
    "Mathematically, for a random variable \"X,\" the CDF is denoted as F(x) and is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "In other words, the CDF at a particular value \"x\" gives the probability that the random variable is less than or equal to \"x.\"\n",
    "\n",
    "Example:\n",
    "Consider a six-sided fair die. Let's define a random variable \"Y\" as the outcome of rolling the die. The CDF of \"Y\" can be represented as:\n",
    "\n",
    "F(y) = P(Y ≤ y)\n",
    "\n",
    "For the die, the CDF could look like this:\n",
    "\n",
    "F(1) = 1/6\n",
    "F(2) = 2/6\n",
    "F(3) = 3/6\n",
    "F(4) = 4/6\n",
    "F(5) = 5/6\n",
    "F(6) = 6/6 = 1\n",
    "\n",
    "This means that the CDF at each value \"y\" gives the probability of rolling a number less than or equal to \"y.\" For example, F(3) = 3/6 = 0.5, which means there's a 50% probability of rolling a number less than or equal to 3.\n",
    "\n",
    "Why CDF is used:\n",
    "\n",
    "1.Provides a Complete View: The CDF provides a comprehensive view of the entire probability distribution of a random variable. It accounts for all values, including those between discrete points in a continuous distribution.\n",
    "\n",
    "2.Calculates Probabilities: The CDF gives the probability that a random variable is less than or equal to a specific value, allowing for the calculation of various probabilities associated with the random variable.\n",
    "\n",
    "3.Comparison and Analysis: CDFs are useful for comparing different distributions or different parameters within the same distribution. They also help in visualizing how probability accumulates as the value of the random variable increases.\n",
    "\n",
    "4.Cumulative Probability: The CDF is particularly useful for understanding the cumulative behavior of a random variable, making it easier to calculate probabilities related to ranges or intervals of values.\n",
    "\n",
    "In summary, the Cumulative Distribution Function is a fundamental concept that provides a comprehensive understanding of the probability distribution of a random variable, enabling calculations and comparisons related to the probabilities of specific values and ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b1dda-e92c-4588-8bd7-d0ff05ed1bd9",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model? \n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a786f-0d86-479f-b774-0a50cb6af320",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, is one of the most important and widely used probability distributions in statistics. It is used to model a wide range of phenomena in various fields. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "1.Height of Individuals: The heights of individuals in a population often follow a normal distribution. This is why the familiar \"bell curve\" is often used to describe the distribution of heights.\n",
    "\n",
    "2.Measurement Errors: When measuring physical quantities with instruments, errors are often normally distributed around the true value. For example, errors in measuring weight, temperature, or time intervals.\n",
    "\n",
    "3.Test Scores: In educational testing, scores on standardized tests such as the SAT or IQ tests are often modeled using the normal distribution.\n",
    "\n",
    "4.Economic Data: Various economic variables like income, stock prices, and GDP growth rates tend to follow a normal distribution.\n",
    "\n",
    "5.Natural Phenomena: Many natural phenomena, like the distribution of speeds of gas molecules or the distribution of errors in astronomical observations, can be modeled with a normal distribution.\n",
    "\n",
    "The normal distribution is defined by two parameters: the mean (μ) and the standard deviation (σ). The mean determines the center of the distribution, and the standard deviation controls the spread or width of the distribution.\n",
    "\n",
    "1.Mean (μ): The mean is the center of the distribution. It represents the average or expected value. Shifting the mean to the left or right on the number line shifts the entire distribution along with it.\n",
    "\n",
    "2.Standard Deviation (σ): The standard deviation measures the spread of the distribution. A larger standard deviation leads to a wider, flatter curve, while a smaller standard deviation results in a narrower, taller curve.\n",
    "\n",
    "The shape of the normal distribution is symmetric around the mean. Approximately 68% of the data falls within one standard deviation of the mean (μ ± σ), about 95% falls within two standard deviations (μ ± 2σ), and about 99.7% falls within three standard deviations (μ ± 3σ). This is known as the empirical rule or the 68-95-99.7 rule.\n",
    "\n",
    "The parameters μ and σ are critical in determining how the normal distribution looks, where its peak is, and how spread out the data is. Different values of μ and σ will result in different shapes of the distribution, allowing the normal distribution to model a wide variety of real-world situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3810b-b611-46e4-a456-c1c5522ba9c3",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal \n",
    "Distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9c09d-2195-4d31-bbb7-0a1722ec9fa4",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, holds immense importance in various fields due to its widespread applicability and several mathematical properties. Here are some reasons for its importance:\n",
    "\n",
    "1.Central Limit Theorem: The normal distribution is a fundamental component of the central limit theorem. This theorem states that the distribution of the sample means from a large enough sample, regardless of the original distribution of the data, will approximate a normal distribution. This property is crucial for statistical inference and hypothesis testing.\n",
    "\n",
    "2.Modeling Real-World Phenomena: Many natural and social phenomena in the real world exhibit characteristics that can be effectively modeled using the normal distribution. This makes it a useful tool for describing and predicting various situations.\n",
    "\n",
    "3.Statistical Analysis: The normal distribution simplifies statistical analysis. Many statistical tests and techniques assume that the data follows a normal distribution, allowing analysts to apply well-established methods for making inferences and drawing conclusions.\n",
    "\n",
    "4.Parameter Estimation: The maximum likelihood estimation method often assumes that the data follows a normal distribution. This simplifies the process of estimating parameters of the distribution.\n",
    "\n",
    "5.Predictive Modeling: In fields like finance and economics, the normal distribution is used as a basis for modeling asset returns, price fluctuations, and economic variables.\n",
    "\n",
    "6.Quality Control: Manufacturing processes often involve measurements that are normally distributed. Quality control efforts utilize the normal distribution to set tolerances and identify anomalies.\n",
    "\n",
    "7.Biological and Behavioral Traits: Characteristics like human height, IQ scores, and blood pressure in a population often follow a normal distribution pattern.\n",
    "\n",
    "Real-Life Examples of Normal Distribution:\n",
    "\n",
    "1.Height of Individuals: Human height is often modeled using a normal distribution. Most people fall close to the average height, and very tall or very short individuals are relatively rare.\n",
    "\n",
    "2.Exam Scores: Scores on standardized tests, like SAT or GRE, tend to follow a normal distribution. Many students score around the average, with fewer at the extremes.\n",
    "\n",
    "3.Temperature Distribution: Daily temperatures in a particular location over a year often exhibit a normal distribution. Average temperatures are most common, and extremely hot or cold days are less frequent.\n",
    "\n",
    "4.Stock Market Returns: Daily changes in stock prices follow a distribution that is approximately normal. Most days, stock prices experience small fluctuations, and larger gains or losses are less common.\n",
    "\n",
    "5.IQ Scores: IQ scores in a population tend to follow a normal distribution. Most people have scores around the average IQ, and very high or very low scores are relatively rare.\n",
    "\n",
    "6.Errors in Measurement: Measurement errors, such as errors in laboratory measurements or instrument readings, often follow a normal distribution pattern.\n",
    "\n",
    "In summary, the normal distribution is a powerful and versatile concept that has applications in a wide range of fields. Its properties and ubiquity make it an essential tool for statistical analysis, modeling, and understanding various real-world phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09eb926-2f8c-43d8-8df6-2e5e590d27e7",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli \n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03a782-f105-44b7-86d3-1276dcf72b39",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (typically denoted as \"1\") and failure (typically denoted as \"0\"). It's the simplest form of a random variable that can take only two values.\n",
    "\n",
    "Mathematically, the probability mass function (PMF) of the Bernoulli distribution is defined as:\n",
    "\n",
    "P(X = x) = p^x * (1 - p)^(1 - x)\n",
    "\n",
    "where:\n",
    "\n",
    "X is the random variable representing the outcome (either 0 or 1).\n",
    "x is the value the random variable takes (0 or 1).\n",
    "p is the probability of success (getting a 1).\n",
    "\n",
    "Example of Bernoulli Distribution:\n",
    "A classic example of the Bernoulli distribution is flipping a fair coin. Let's say we define the random variable \"X\" as follows:\n",
    "\n",
    "X = 1 if the coin lands heads (success).\n",
    "X = 0 if the coin lands tails (failure).\n",
    "In this case, the probability of success (getting heads) is p = 0.5, and the probability of failure (getting tails) is 1 - p = 0.5.\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "1.Number of Trials:\n",
    "\n",
    "Bernoulli Distribution: Represents a single trial or experiment with two possible outcomes.\n",
    "Binomial Distribution: Represents multiple independent Bernoulli trials (experiments), each with the same probability of success.\n",
    "\n",
    "2.Number of Outcomes:\n",
    "\n",
    "Bernoulli Distribution: Has two possible outcomes: success (1) and failure (0).\n",
    "Binomial Distribution: Models the number of successes (1s) in a fixed number of trials.\n",
    "\n",
    "3.Probability Parameter:\n",
    "\n",
    "Bernoulli Distribution: Has a single parameter, p, which represents the probability of success.\n",
    "Binomial Distribution: Has two parameters: n (number of trials) and p (probability of success).\n",
    "\n",
    "4.Probability Mass Function (PMF):\n",
    "\n",
    "Bernoulli Distribution: PMF is P(X = x) = p^x * (1 - p)^(1 - x) for x = 0 or 1.\n",
    "Binomial Distribution: PMF is the binomial coefficient multiplied by the probability of success raised to the power of the number of successes, and the probability of failure raised to the power of the number of failures.\n",
    "\n",
    "5.Use Cases:\n",
    "\n",
    "Bernoulli Distribution: Used for modeling single yes/no events with a constant probability of success.\n",
    "Binomial Distribution: Used for modeling the number of successes in a fixed number of independent trials with the same probability of success.\n",
    "\n",
    "In summary, the Bernoulli distribution is a special case of the binomial distribution where there's only one trial. The key distinction is that the Bernoulli distribution models the outcome of a single experiment, while the binomial distribution models the number of successes in a fixed number of independent experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022c6ee-f601-4e6e-bd7a-df2952c6c5f0",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset \n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater \n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df82547-770f-4cba-ae0b-12cb3ccd9272",
   "metadata": {},
   "source": [
    "To calculate the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60, we need to use the standard normal distribution (Z) and the z-score formula.\n",
    "\n",
    "The z-score is calculated as:\n",
    "\n",
    "\n",
    "z = (x - μ) / σ\n",
    "where:\n",
    "\n",
    "x is the value we want to calculate the probability for (in this case, 60).\n",
    "μ is the mean of the distribution (given as 50).\n",
    "σ is the standard deviation of the distribution (given as 10).\n",
    "\n",
    "Substitute the values into the formula:\n",
    "\n",
    "\n",
    "z = (60 - 50) / 10\n",
    "z = 1\n",
    "Now, we need to find the probability associated with this z-score using the standard normal distribution table or calculator. The probability that a z-score is greater than 1 can be calculated as:\n",
    "\n",
    "\n",
    "P(Z > 1) = 1 - P(Z ≤ 1)\n",
    "Looking up the value of the cumulative distribution function (CDF) for z = 1 in the standard normal distribution table (or using a calculator), we find that P(Z ≤ 1) ≈ 0.8413.\n",
    "\n",
    "Therefore,\n",
    "\n",
    "P(Z > 1) = 1 - 0.8413 = 0.1587\n",
    "So, the probability that a randomly selected observation from this normally distributed dataset will be greater than 60 is approximately 0.1587, or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5bcaa-cc7c-48bc-b04c-b1996e8b6df2",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60071f-20d5-464a-8089-e813cdeaa770",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "The uniform distribution, also known as the rectangular distribution, is a probability distribution where all outcomes in a given interval are equally likely. In other words, in a uniform distribution, every value within a specified range has the same probability of being observed. It's characterized by a constant probability density function (PDF) over the interval.\n",
    "\n",
    "Mathematically, the PDF of a uniform distribution is defined as:\n",
    "\n",
    "f(x) = 1 / (b - a)   for a ≤ x ≤ b\n",
    "\n",
    "where:\n",
    "\n",
    "a is the lower bound of the interval.\n",
    "b is the upper bound of the interval.\n",
    "\n",
    "In a uniform distribution, the probability of observing any value between a and b is the same, and the probability outside this interval is zero.\n",
    "\n",
    "Example of Uniform Distribution:\n",
    "Suppose you have a six-sided fair die. Each face of the die is numbered from 1 to 6. If the die is fair, each face has an equal chance of landing face up when rolled. This situation can be modeled using a discrete uniform distribution.\n",
    "\n",
    "For the discrete uniform distribution of the die, the probabilities are as follows:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "This means that each outcome (rolling a particular number) has an equal probability of 1/6.\n",
    "\n",
    "For a continuous uniform distribution, consider a scenario where you have a random number generator that generates numbers between 0 and 1 (inclusive). If this generator is truly uniform, each number in this range has an equal probability of being generated.\n",
    "\n",
    "In summary, the uniform distribution is used to model situations where all possible outcomes within a specific interval are equally likely. It's commonly used in scenarios involving random sampling, random number generation, and situations where each possible outcome has an equal chance of occurring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c70bef6-cdbc-428b-af70-504eb512b02a",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d81dcf4-8f61-4028-95a8-cf97ced763f4",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "The z-score, also known as the standard score, is a statistical measure that quantifies the number of standard deviations a data point is from the mean of a dataset. It's a dimensionless value that allows us to compare and standardize data points from different distributions.\n",
    "\n",
    "The formula to calculate the z-score for a data point \"x\" in a dataset with mean \"μ\" and standard deviation \"σ\" is:\n",
    "\n",
    "\n",
    "z = (x - μ) / σ\n",
    "The z-score indicates how many standard deviations a particular data point is away from the mean. A positive z-score indicates that the data point is above the mean, while a negative z-score indicates that it's below the mean.\n",
    "\n",
    "Importance of the z-score:\n",
    "\n",
    "1.Standardization and Comparison: The z-score standardizes data, making it possible to compare data from different distributions with varying means and standard deviations. This is particularly useful in comparing values that belong to different units or scales.\n",
    "\n",
    "2.Outlier Detection: Large z-scores (either positive or negative) can indicate outliers—data points that are unusually far from the mean. They might suggest data entry errors or interesting phenomena.\n",
    "\n",
    "3.Normal Distribution Analysis: In a standard normal distribution (mean = 0, standard deviation = 1), the z-score directly corresponds to the percentile rank of a data point. This allows for easy calculations of probabilities associated with specific data values.\n",
    "\n",
    "4.Hypothesis Testing: In hypothesis testing, the z-score is used to determine whether an observed difference between groups is statistically significant. It helps in making decisions about accepting or rejecting hypotheses.\n",
    "\n",
    "5.Data Transformation: Z-scores can be used to transform data to achieve a specific mean and standard deviation. This is useful in data preprocessing and normalization.\n",
    "\n",
    "6.Data Exploration: Z-scores are used to identify data points that might require further investigation due to their extreme values.\n",
    "\n",
    "In summary, the z-score is a versatile tool that helps standardize data, enabling comparisons and analysis across different distributions. It's used in a variety of statistical and analytical techniques to understand relationships between data points and to make informed decisions based on their relative positions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df0f68-aa7f-4b94-b394-cf53c6839a97",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a73ca-a800-462e-ac32-ab319a8e4379",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the sampling distribution of the mean (or sum) of a sufficiently large number of independent, identically distributed random variables will be approximately normally distributed, regardless of the original distribution of the individual variables. In simpler terms, even if the population distribution is not normal, the distribution of sample means tends to become normal as the sample size increases.\n",
    "\n",
    "The Central Limit Theorem can be stated as follows:\n",
    "\n",
    "Given a population with any shape of distribution (not necessarily normal) and a sufficiently large sample size \"n,\" the distribution of the sample means (or sum) will approach a normal distribution with a mean equal to the population mean (μ) and a standard deviation equal to the population standard deviation (σ) divided by the square root of the sample size (√n).\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "1.Allows for Inference: The CLT is the basis for many statistical inference techniques, including hypothesis testing, confidence intervals, and regression analysis. It justifies the use of normal-based methods even when the population distribution is not normal.\n",
    "\n",
    "2.Real-World Applicability: In many real-world scenarios, the distribution of sample means tends to resemble a normal distribution, even if the underlying population is not normal. This makes statistical analysis more practical and accessible.\n",
    "\n",
    "3.Sampling Error Control: The CLT helps in understanding how sampling error behaves as the sample size increases. It shows that larger sample sizes result in smaller sampling variability and better approximations of normality.\n",
    "\n",
    "4.Estimation Improvement: When dealing with unknown population parameters, like the mean or variance, the CLT allows for better estimation through the use of normal distribution properties.\n",
    "\n",
    "5.Large-Scale Data Analysis: In fields like data science, where large datasets are common, the CLT allows practitioners to assume normality of sample means for various analyses, which simplifies complex calculations.\n",
    "\n",
    "6.Design of Experiments: The CLT is essential for designing experiments and sample size determination. It guides researchers on how to choose appropriate sample sizes for valid statistical analysis.\n",
    "\n",
    "7.Foundation for More Complex Distributions: The CLT serves as a foundational concept that facilitates the understanding of more complex distributions like the t-distribution and F-distribution.\n",
    "\n",
    "In essence, the Central Limit Theorem is crucial because it provides a bridge between the characteristics of a population and the properties of sample means, making it possible to draw meaningful conclusions and perform various statistical analyses even when the population distribution is not known or normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa542d5a-9d3f-4852-8ffe-b977a34f6074",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a15730-cf2c-48b3-b6fd-a974ed2bea18",
   "metadata": {},
   "source": [
    "Ans :-\n",
    "The Central Limit Theorem (CLT) is a powerful statistical concept, but it comes with certain assumptions that need to be met in order for the theorem to hold. These assumptions ensure that the distribution of sample means becomes approximately normal as the sample size increases. The assumptions of the Central Limit Theorem are as follows:\n",
    "\n",
    "1.Independence: The observations or data points within each sample must be independent of each other. This means that the value of one observation should not influence the value of another observation.\n",
    "\n",
    "2.Identical Distribution: The observations in each sample must come from the same population and follow the same underlying distribution. This ensures that the random variables being averaged have the same properties.\n",
    "\n",
    "3.Finite Variance: The population distribution from which the samples are drawn must have a finite variance. This ensures that the mean and standard deviation are well-defined and finite.\n",
    "\n",
    "4.Sample Size: The sample size should be sufficiently large. While there is no strict rule for what constitutes a \"sufficiently large\" sample size, a common guideline is that the sample size should be at least 30. However, this number can vary depending on the original distribution and the degree of skewness.\n",
    "\n",
    "It's important to note that the Central Limit Theorem is more robust and applicable when the sample size is larger and the underlying population distribution is not extremely skewed or heavy-tailed. Additionally, while the CLT allows for approximations of normality, the accuracy of the approximation can depend on how well the assumptions are met.\n",
    "\n",
    "In practice, if the assumptions of the Central Limit Theorem are not met, the theorem may not hold, and other statistical techniques or methods may need to be considered for inference and analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
